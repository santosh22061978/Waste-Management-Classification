{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from imutils import paths\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "path_to_zip_file = \"/floyd/home/datasets/waste-classification-data-v2.zip\"\n",
    "directory_to_extract_to = \"/floyd/home/datasets/input\"\n",
    "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(directory_to_extract_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dDELETE FILES FROM TRAIN AND TEST FOLDER TO RECREATE IT\n",
    "import os, shutil\n",
    "def delete_File(folderpath):\n",
    "    for filename in os.listdir(folderpath):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/floyd/home/datasets/train'\n",
    "#folder = '/floyd/home/datasets/input/DATASET/TRAIN/N'\n",
    "\n",
    "delete_File(folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##folder = '/floyd/home/datasets/input/DATASET/TRAIN'\n",
    "\n",
    "#delete_File(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir = 'waste-classification-data-v2\\\\DATASET\\\\'\n",
    "train_data_N = '/floyd/home/datasets/input/DATASET/TRAIN/N'\n",
    "train_data_o = '/floyd/home/datasets/input/DATASET/TRAIN/O'\n",
    "train_data_r = '/floyd/home/datasets/input/DATASET/TRAIN/R'\n",
    "test_data_N = '/floyd/home/datasets/input/DATASET/TEST/N'\n",
    "test_data_o = '/floyd/home/datasets/input/DATASET/TEST/O'\n",
    "test_data_r = '/floyd/home/datasets/input/DATASET/TEST/R'\n",
    "#index =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading example image...\n"
     ]
    }
   ],
   "source": [
    "##### regenerate images for class 'o' or N class to create balanced data ###################\n",
    "############## ALREADY DONE DO NEED TO RUN ONCE AGAIN\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "import numpy as np\n",
    "import os\n",
    "# load the input image, convert it to a NumPy array, and then\n",
    "# reshape it to have an extra dimension\n",
    "print(\"[INFO] loading example image...\")\n",
    "train_data_N = '/floyd/home/datasets/input/DATASET/TRAIN/N'\n",
    "new_data_N =  '/floyd/home/datasets/input/DATASET/TRAIN/N'\n",
    "#image = load_img('/floyd/home/datasets/test/00000281.jpg')\n",
    "paths = os.listdir(train_data_N)\n",
    "for imagepath in paths:\n",
    "    image = load_img(train_data_N +\"/\"+imagepath)\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    # construct the image generator for data augmentation then\n",
    "    # initialize the total number of images generated thus far\n",
    "    aug = ImageDataGenerator(rotation_range=20, width_shift_range=0.2,height_shift_range=0.1, \n",
    "                shear_range=0.2, zoom_range=0.2,horizontal_flip=True, fill_mode=\"nearest\")\n",
    "    total = 0\n",
    "\n",
    "    # construct the actual Python generator\n",
    "    #print(\"[INFO] generating images...\")\n",
    "    imageGen = aug.flow(image, batch_size=1, save_to_dir=new_data_N,save_prefix='new_aug',\n",
    "                        save_format=\"jpg\")\n",
    "\n",
    "    # loop over examples from our image data augmentation generator\n",
    "    for image in imageGen:\n",
    "        # increment our counter\n",
    "        total += 1\n",
    "\n",
    "        # if we have reached 10 examples, break from the loop\n",
    "        if total == 4:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create csv file for train and test data\n",
    "imagepaths_train = []\n",
    "imagepaths_train.append(train_data_N)\n",
    "imagepaths_train.append(train_data_o)\n",
    "imagepaths_train.append(train_data_r)\n",
    "imagepaths_test = []\n",
    "imagepaths_test.append(test_data_N)\n",
    "imagepaths_test.append(test_data_o)\n",
    "imagepaths_test.append(test_data_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data_dataframe(dataframe,directory,labelPath,class_id,indx =0):\n",
    "    #paths = os.listdir('/floyd/home/datasets/input/DATASET/TRAIN/O')\n",
    "    paths = os.listdir(directory)\n",
    "    #paths = directory\n",
    "    print(indx)\n",
    "    #print(paths)\n",
    "    #print(paths)\n",
    "\n",
    "\n",
    "    for image in paths:\n",
    "        dataframe.loc[indx,'id_code'] = image\n",
    "        dataframe.loc[indx,'path'] = labelPath +\"/\"+image\n",
    "        dataframe.loc[indx,'category'] = class_id\n",
    "        # construct the path to the destination image and then copy\n",
    "        # the image itself\n",
    "        p = os.path.sep.join([labelPath, image])\n",
    "#         print(p)\n",
    "#         print('labelPath +\"/\"+image')\n",
    "#         print(labelPath +\"/\"+image)\n",
    "#         print(directory +\"/\"+image)\n",
    "        shutil.copy2(directory +\"/\"+image, p)\n",
    "        indx +=1 \n",
    "    return indx    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "12565\n",
      "19717\n"
     ]
    }
   ],
   "source": [
    "#loop over the input images\n",
    "data_table = pd.DataFrame(columns=['id_code','path','category'])\n",
    "labelpath = \"/floyd/home/datasets/train\"\n",
    "index =0\n",
    "index = add_data_dataframe(dataframe= data_table,directory=train_data_o,labelPath =labelpath,class_id=1,indx=index)\n",
    "index = add_data_dataframe(dataframe= data_table,directory=train_data_r,labelPath =labelpath,class_id=2,indx=index)\n",
    "index = add_data_dataframe(dataframe= data_table,directory=train_data_N,labelPath =labelpath,class_id=0,indx=index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the dataframe \n",
    "data_table.to_csv('/floyd/home/datasets/train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table.path.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12565</td>\n",
       "      <td>9627</td>\n",
       "      <td>7152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1     0     2\n",
       "count  12565  9627  7152"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the value in count\n",
    "data_table = pd.read_csv('/floyd/home/datasets/train.csv') \n",
    "data_table.category.value_counts().to_frame(name='count').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after adding new data for class N\n",
    "# display the value in count\n",
    "data_table.category.value_counts().to_frame(name='count').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    42.819656\n",
       "0    32.807388\n",
       "2    24.372955\n",
       "Name: category, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the data in percentage\n",
    "data_table.category.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_table.groupby('category')['path']\n",
    "grouped = data_table.groupby('category')\n",
    "df_sample =grouped.apply(lambda x: x.sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(filename):    \n",
    "    image = plt.imread(filename)\n",
    "    #<something gets done here>\n",
    "    plt.figure()\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df_sample.iterrows():\n",
    "    #print(str(row[1][1]))\n",
    "    process(str(row[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1401\n",
      "2513\n"
     ]
    }
   ],
   "source": [
    "#loop over the input images\n",
    "data_table = pd.DataFrame(columns=['id_code','path','category'])\n",
    "labelpath = \"/floyd/home/datasets/test\"\n",
    "index =0\n",
    "index = add_data_dataframe(dataframe= data_table,directory=test_data_o,labelPath =labelpath,class_id=1,indx=index)\n",
    "index = add_data_dataframe(dataframe= data_table,directory=test_data_r,labelPath =labelpath,class_id=2,indx=index)\n",
    "index = add_data_dataframe(dataframe= data_table,directory=test_data_N,labelPath =labelpath,class_id=0,indx=index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the dataframe \n",
    "data_table.to_csv('/floyd/home/datasets/test.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the data in percentage\n",
    "data_table.category.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedtest = data_table.groupby('category')\n",
    "df_sampletest =groupedtest.apply(lambda x: x.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df_sampletest.iterrows():\n",
    "    process(str(row[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-28 18:30:40.233199\n",
      "[INFO] building /floyd/home/datasets/train.hdf5...\n",
      "[INFO] building /floyd/home/datasets/val.hdf5...\n",
      "[INFO] building /floyd/home/datasets/test.hdf5...\n",
      "[INFO] serializing means...\n",
      "2020-02-28 18:31:55.932602\n"
     ]
    }
   ],
   "source": [
    "import hdf5datacreator_128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "initialize the preprocessors\n",
      "initialize the preprocessors done\n",
      " initialize the training and validation dataset generators\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 3s 0us/step\n",
      "[INFO] re-compiling model...\n",
      "[INFO] training head...\n",
      "[INFO] fine-tuning model...\n",
      "Epoch 1/50\n",
      "733/733 [==============================] - 283s 386ms/step - loss: 0.8009 - acc: 0.6782 - val_loss: 0.5959 - val_acc: 0.7440\n",
      "Epoch 2/50\n",
      "733/733 [==============================] - 232s 316ms/step - loss: 0.5384 - acc: 0.7730 - val_loss: 0.5290 - val_acc: 0.7843\n",
      "Epoch 3/50\n",
      "733/733 [==============================] - 229s 312ms/step - loss: 0.4686 - acc: 0.8089 - val_loss: 0.4076 - val_acc: 0.8329\n",
      "Epoch 4/50\n",
      "733/733 [==============================] - 228s 312ms/step - loss: 0.4217 - acc: 0.8300 - val_loss: 0.3812 - val_acc: 0.8468\n",
      "Epoch 5/50\n",
      "733/733 [==============================] - 228s 311ms/step - loss: 0.3844 - acc: 0.8494 - val_loss: 0.3831 - val_acc: 0.8451\n",
      "Epoch 6/50\n",
      "733/733 [==============================] - 229s 312ms/step - loss: 0.3566 - acc: 0.8600 - val_loss: 0.3439 - val_acc: 0.8669\n",
      "Epoch 7/50\n",
      "733/733 [==============================] - 228s 311ms/step - loss: 0.3323 - acc: 0.8701 - val_loss: 0.3472 - val_acc: 0.8682\n",
      "Epoch 8/50\n",
      "733/733 [==============================] - 228s 311ms/step - loss: 0.3097 - acc: 0.8792 - val_loss: 0.3576 - val_acc: 0.8609\n",
      "Epoch 9/50\n",
      "733/733 [==============================] - 228s 312ms/step - loss: 0.2937 - acc: 0.8875 - val_loss: 0.4257 - val_acc: 0.8281\n",
      "Epoch 10/50\n",
      "733/733 [==============================] - 228s 311ms/step - loss: 0.2740 - acc: 0.8925 - val_loss: 0.3971 - val_acc: 0.8449\n",
      "Epoch 11/50\n",
      "733/733 [==============================] - 228s 312ms/step - loss: 0.2589 - acc: 0.9028 - val_loss: 0.3569 - val_acc: 0.8588\n",
      "Epoch 12/50\n",
      "733/733 [==============================] - 228s 312ms/step - loss: 0.2482 - acc: 0.9046 - val_loss: 0.3626 - val_acc: 0.8677\n",
      "Epoch 13/50\n",
      "733/733 [==============================] - 228s 311ms/step - loss: 0.2346 - acc: 0.9090 - val_loss: 0.3256 - val_acc: 0.8826\n",
      "Epoch 14/50\n",
      "733/733 [==============================] - 228s 312ms/step - loss: 0.2252 - acc: 0.9144 - val_loss: 0.2998 - val_acc: 0.8891\n",
      "Epoch 15/50\n",
      "733/733 [==============================] - 228s 311ms/step - loss: 0.2132 - acc: 0.9214 - val_loss: 0.3022 - val_acc: 0.8890\n",
      "Epoch 16/50\n",
      "733/733 [==============================] - 228s 311ms/step - loss: 0.2027 - acc: 0.9227 - val_loss: 0.2986 - val_acc: 0.8920\n",
      "Epoch 17/50\n",
      "733/733 [==============================] - 228s 311ms/step - loss: 0.1966 - acc: 0.9257 - val_loss: 0.2856 - val_acc: 0.8968\n",
      "Epoch 18/50\n",
      "733/733 [==============================] - 228s 311ms/step - loss: 0.1842 - acc: 0.9309 - val_loss: 0.3060 - val_acc: 0.8956\n",
      "Epoch 19/50\n",
      "733/733 [==============================] - 228s 311ms/step - loss: 0.1738 - acc: 0.9354 - val_loss: 0.3298 - val_acc: 0.8811\n",
      "Epoch 20/50\n",
      "733/733 [==============================] - 228s 311ms/step - loss: 0.1694 - acc: 0.9362 - val_loss: 0.2818 - val_acc: 0.9094\n",
      "Epoch 21/50\n",
      "733/733 [==============================] - 228s 311ms/step - loss: 0.1606 - acc: 0.9401 - val_loss: 0.2661 - val_acc: 0.9071\n",
      "Epoch 22/50\n",
      "733/733 [==============================] - 228s 311ms/step - loss: 0.1490 - acc: 0.9443 - val_loss: 0.2783 - val_acc: 0.9123\n",
      "Epoch 23/50\n",
      "733/733 [==============================] - 228s 311ms/step - loss: 0.1485 - acc: 0.9466 - val_loss: 0.2891 - val_acc: 0.9034\n",
      "Epoch 24/50\n",
      "733/733 [==============================] - 228s 311ms/step - loss: 0.1369 - acc: 0.9479 - val_loss: 0.2855 - val_acc: 0.9040\n",
      "Epoch 25/50\n",
      "733/733 [==============================] - 228s 311ms/step - loss: 0.1386 - acc: 0.9498 - val_loss: 0.2667 - val_acc: 0.9155\n",
      "Epoch 26/50\n",
      "733/733 [==============================] - 228s 311ms/step - loss: 0.1290 - acc: 0.9538 - val_loss: 0.2549 - val_acc: 0.9212\n",
      "Epoch 27/50\n",
      "733/733 [==============================] - 228s 311ms/step - loss: 0.1197 - acc: 0.9557 - val_loss: 0.4011 - val_acc: 0.8830\n",
      "Epoch 28/50\n",
      "733/733 [==============================] - 228s 311ms/step - loss: 0.1174 - acc: 0.9571 - val_loss: 0.4353 - val_acc: 0.8725\n",
      "Epoch 29/50\n",
      "733/733 [==============================] - 227s 310ms/step - loss: 0.1123 - acc: 0.9604 - val_loss: 0.2510 - val_acc: 0.9273\n",
      "Epoch 30/50\n",
      "733/733 [==============================] - 227s 310ms/step - loss: 0.1060 - acc: 0.9621 - val_loss: 0.2391 - val_acc: 0.9297\n",
      "Epoch 31/50\n",
      "733/733 [==============================] - 227s 310ms/step - loss: 0.1046 - acc: 0.9621 - val_loss: 0.2688 - val_acc: 0.9198\n",
      "Epoch 32/50\n",
      "733/733 [==============================] - 227s 310ms/step - loss: 0.0989 - acc: 0.9643 - val_loss: 0.2966 - val_acc: 0.9202\n",
      "Epoch 33/50\n",
      "733/733 [==============================] - 227s 310ms/step - loss: 0.0952 - acc: 0.9653 - val_loss: 0.3026 - val_acc: 0.9138\n",
      "Epoch 34/50\n",
      "733/733 [==============================] - 227s 310ms/step - loss: 0.0901 - acc: 0.9679 - val_loss: 0.2971 - val_acc: 0.9143\n",
      "Epoch 35/50\n",
      "733/733 [==============================] - 227s 310ms/step - loss: 0.0855 - acc: 0.9702 - val_loss: 0.3763 - val_acc: 0.8960\n",
      "Epoch 36/50\n",
      "733/733 [==============================] - 227s 310ms/step - loss: 0.0858 - acc: 0.9690 - val_loss: 0.2752 - val_acc: 0.9256\n",
      "Epoch 37/50\n",
      "733/733 [==============================] - 227s 310ms/step - loss: 0.0814 - acc: 0.9716 - val_loss: 0.2677 - val_acc: 0.9282\n",
      "Epoch 38/50\n",
      "733/733 [==============================] - 227s 310ms/step - loss: 0.0826 - acc: 0.9703 - val_loss: 0.3337 - val_acc: 0.9088\n",
      "Epoch 39/50\n",
      "733/733 [==============================] - 227s 310ms/step - loss: 0.0742 - acc: 0.9732 - val_loss: 0.3110 - val_acc: 0.9106\n",
      "Epoch 40/50\n",
      "733/733 [==============================] - 227s 310ms/step - loss: 0.0718 - acc: 0.9748 - val_loss: 0.2681 - val_acc: 0.9289\n",
      "Epoch 41/50\n",
      "733/733 [==============================] - 227s 310ms/step - loss: 0.0692 - acc: 0.9757 - val_loss: 0.3467 - val_acc: 0.9095\n",
      "Epoch 42/50\n",
      "733/733 [==============================] - 227s 310ms/step - loss: 0.0690 - acc: 0.9762 - val_loss: 0.2695 - val_acc: 0.9292\n",
      "Epoch 43/50\n",
      "733/733 [==============================] - 227s 310ms/step - loss: 0.0630 - acc: 0.9777 - val_loss: 0.2812 - val_acc: 0.9289\n",
      "Epoch 44/50\n",
      "733/733 [==============================] - 227s 309ms/step - loss: 0.0603 - acc: 0.9791 - val_loss: 0.2856 - val_acc: 0.9256\n",
      "Epoch 45/50\n",
      "733/733 [==============================] - 227s 309ms/step - loss: 0.0609 - acc: 0.9781 - val_loss: 0.3426 - val_acc: 0.9087\n",
      "Epoch 46/50\n",
      "733/733 [==============================] - 227s 309ms/step - loss: 0.0576 - acc: 0.9799 - val_loss: 0.3858 - val_acc: 0.9023\n",
      "Epoch 47/50\n",
      "733/733 [==============================] - 226s 309ms/step - loss: 0.0556 - acc: 0.9806 - val_loss: 0.2717 - val_acc: 0.9332\n",
      "Epoch 48/50\n",
      "733/733 [==============================] - 227s 309ms/step - loss: 0.0523 - acc: 0.9807 - val_loss: 0.2779 - val_acc: 0.9294\n",
      "Epoch 49/50\n",
      "733/733 [==============================] - 227s 309ms/step - loss: 0.0531 - acc: 0.9813 - val_loss: 0.2787 - val_acc: 0.9304\n",
      "Epoch 50/50\n",
      "733/733 [==============================] - 226s 309ms/step - loss: 0.0513 - acc: 0.9819 - val_loss: 0.2801 - val_acc: 0.9328\n"
     ]
    }
   ],
   "source": [
    "import finetune_waste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n",
      "[INFO] evaluating after initialization...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.64      0.59       397\n",
      "           1       0.89      0.98      0.93      1401\n",
      "           2       0.84      0.69      0.76      1112\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      2910\n",
      "   macro avg       0.76      0.77      0.76      2910\n",
      "weighted avg       0.83      0.82      0.82      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from simpledatasetloader import SimpleDatasetLoader\n",
    "from imagetoarraypreprocessor import ImageToArrayPreprocessor\n",
    "from simplepreprocessor import SimplePreprocessor\n",
    "from meanpreprocessor import MeanPreprocessor\n",
    "from aspectawarepreprocessor import AspectAwarePreprocessor\n",
    "import pandas as pd\n",
    "import config\n",
    "import json\n",
    "from keras.models import load_model\n",
    "\n",
    "means = json.loads(open(config.DATASET_MEAN).read())\n",
    "# initialize the image preprocessors\n",
    "\n",
    "aap = AspectAwarePreprocessor(128, 128)\n",
    "mp = MeanPreprocessor(means[\"R\"], means[\"G\"], means[\"B\"])\n",
    "#cp = CropPreprocessor(227, 227)\n",
    "iap = ImageToArrayPreprocessor()\n",
    "\n",
    "# load the dataset from disk then scale the raw pixel intensities to\n",
    "# the range [0, 1]\n",
    "sdl = SimpleDatasetLoader(preprocessors=[aap,mp, iap])\n",
    "#imagePaths = list('/floyd/home/datasets/test')\n",
    "dftest = pd.read_csv('/floyd/home/datasets/test.csv')\n",
    "\n",
    "#shuffle dataframe in-place and reset the index\n",
    "dftest = dftest.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "imagePaths = dftest.path.values.tolist()\n",
    "Labels=dftest.category.values.tolist()\n",
    "(data, labels) = sdl.load(imagePaths,Labels, verbose=500)\n",
    "#data = data.astype(\"float\") / 255.0\n",
    "# load the pretrained network\n",
    "print(\"[INFO] loading model...\")\n",
    "model = load_model(config.Model_PATH)\n",
    "\n",
    "# evaluate the network after initialization\n",
    "print(\"[INFO] evaluating after initialization...\")\n",
    "predictions = model.predict(data, batch_size=32)\n",
    "classNames = {0: \"Non-Recyclable\", 1: \"Organic\", 2: \"Recyclable\"}\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "print(classification_report(labels,predictions.argmax(axis=1)))              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/dist-packages/requests/__init__.py:83: RequestsDependencyWarning: Old version of cryptography ([1, 2, 3]) may cause slowdown.\n",
      "  warnings.warn(warning, RequestsDependencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "initialize the preprocessors\n",
      "initialize the preprocessors done\n",
      " initialize the training and validation dataset generators\n",
      "[INFO] compiling model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 21,138,243\n",
      "Trainable params: 6,423,555\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "[INFO] Training model...\n",
      "23476\n",
      "5868\n",
      "2020-02-24 16:38:50.884121\n",
      "Epoch 1/40\n"
     ]
    }
   ],
   "source": [
    "import trainmodelwaste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "initialize the preprocessors\n",
      "initialize the preprocessors done\n",
      " initialize the training and validation dataset generators\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 3s 0us/step\n",
      "[INFO] re-compiling model...\n",
      "[INFO] training head...\n",
      "[INFO] fine-tuning model...\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "import finetune_waste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from imagetoarraypreprocessor import ImageToArrayPreprocessor\n",
    "from simplepreprocessor import SimplePreprocessor\n",
    "from meanpreprocessor import MeanPreprocessor\n",
    "from sklearn.metrics import classification_report\n",
    "from hdf5datasetgenerator import HDF5DatasetGenerator\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "#import progressbar\n",
    "import json\n",
    "\n",
    "# load the RGB means for the training set\n",
    "means = json.loads(open(config.DATASET_MEAN).read())\n",
    "\n",
    "# initialize the image preprocessors\n",
    "sp = SimplePreprocessor(224, 224)\n",
    "mp = MeanPreprocessor(means[\"R\"], means[\"G\"], means[\"B\"])\n",
    "#cp = CropPreprocessor(227, 227)\n",
    "iap = ImageToArrayPreprocessor()\n",
    "#\n",
    "# load the pretrained network\n",
    "print(\"[INFO] loading model...\")\n",
    "model = load_model(config.Model_PATH)\n",
    "#\n",
    "classNames = {0: \"Non-Recyclable\", 1: \"Organic\", 2: \"Recyclable\"}\n",
    "# initialize the testing dataset generator, then make predictions on\n",
    "# the testing data\n",
    "print(\"[INFO] predicting on test data (no crops)...\")\n",
    "testGen = HDF5DatasetGenerator(config.TEST_HDF5, 32,preprocessors=[sp, mp, iap], classes=len(classNames))\n",
    "\n",
    "# reset the testing generator and then use our trained model to\n",
    "# make predictions on the data\n",
    "predictions = model.predict_generator(testGen.generator(),steps=testGen.numImages // 32, max_queue_size=10)\n",
    "\n",
    "print(classification_report(testGen.db[\"labels\"],predictions.argmax(axis=1), target_names=classNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpledatasetloader import SimpleDatasetLoader\n",
    "from imagetoarraypreprocessor import ImageToArrayPreprocessor\n",
    "from simplepreprocessor import SimplePreprocessor\n",
    "from meanpreprocessor import MeanPreprocessor\n",
    "from aspectawarepreprocessor import AspectAwarePreprocessor\n",
    "import pandas as pd\n",
    "import config\n",
    "import json\n",
    "from keras.models import load_model\n",
    "\n",
    "means = json.loads(open(config.DATASET_MEAN).read())\n",
    "# initialize the image preprocessors\n",
    "\n",
    "aap = AspectAwarePreprocessor(224, 224)\n",
    "mp = MeanPreprocessor(means[\"R\"], means[\"G\"], means[\"B\"])\n",
    "#cp = CropPreprocessor(227, 227)\n",
    "iap = ImageToArrayPreprocessor()\n",
    "\n",
    "# load the dataset from disk then scale the raw pixel intensities to\n",
    "# the range [0, 1]\n",
    "sdl = SimpleDatasetLoader(preprocessors=[aap,mp, iap])\n",
    "#imagePaths = list('/floyd/home/datasets/test')\n",
    "dftest = pd.read_csv('/floyd/home/datasets/test.csv')\n",
    "\n",
    "#shuffle dataframe in-place and reset the index\n",
    "dftest = dftest.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "imagePaths = dftest.path.values.tolist()\n",
    "Labels=dftest.category.values.tolist()\n",
    "(data, labels) = sdl.load(imagePaths,Labels, verbose=500)\n",
    "#data = data.astype(\"float\") / 255.0\n",
    "# load the pretrained network\n",
    "print(\"[INFO] loading model...\")\n",
    "model = load_model(config.Model_PATH)\n",
    "\n",
    "# evaluate the network after initialization\n",
    "print(\"[INFO] evaluating after initialization...\")\n",
    "predictions = model.predict(data, batch_size=32)\n",
    "classNames = {0: \"Non-Recyclable\", 1: \"Organic\", 2: \"Recyclable\"}\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "print(classification_report(labels,predictions.argmax(axis=1)))              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "print(classification_report(labels,predictions.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv( config.BASE_PATH +'/train.csv')\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing for single image on test data for class zero (0)\n",
    "import pandas as pd\n",
    "import config\n",
    "import json\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "import h5py\n",
    "import cv2\n",
    "import os\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "\n",
    "means = json.loads(open(config.DATASET_MEAN).read())\n",
    "# initialize the image preprocessors\n",
    "# load the image for classification\n",
    "images = []\n",
    "#folder =\"c:\\image-classification-keras\\examples\"\n",
    "model = load_model(config.Model_PATH)\n",
    "image = cv2.imread('/floyd/home/datasets/test/00000281.jpg')\n",
    "if image is not None:\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = image.astype(\"float\") / 255.0\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    images.append(image)\n",
    "    testimage = model.predict(image)[0]\n",
    "print(testimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import finetune_waste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
